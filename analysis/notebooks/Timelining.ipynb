{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79a946-5727-431a-8abd-ef12e0351800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "env_path = Path('..') / '.env.local'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Retrieve credentials\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "username = os.getenv(\"NEO4J_USER\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "BOT_TOKEN = os.getenv(\"BOT_TOKEN\")\n",
    "\n",
    "print(uri)\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4a3be-699c-4611-a065-59122c1eefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(tx):\n",
    "    result = tx.run(\"CALL db.schema.visualization()\")\n",
    "    return result.single()\n",
    "\n",
    "\n",
    "with driver.session() as session:\n",
    "    schema = session.read_transaction(get_schema)\n",
    "\n",
    "# Extract nodes and relationships\n",
    "node_labels = [list(node.labels)[0] for node in schema[\"nodes\"]]\n",
    "print(\"Node Labels:\", node_labels)\n",
    "\n",
    "relationships = schema[\"relationships\"]\n",
    "\n",
    "rel_summary = []\n",
    "for rel in relationships:\n",
    "    source_label = list(rel.nodes[0].labels)[0]\n",
    "    target_label = list(rel.nodes[1].labels)[0]\n",
    "    rel_type = rel.type\n",
    "    rel_summary.append((source_label, rel_type, target_label))\n",
    "\n",
    "# Print nicely\n",
    "for source, rel_type, target in rel_summary:\n",
    "    print(f\"{source} -[{rel_type}]-> {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9cd627-f89c-426f-80fd-061b1ed66c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cypher(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return pd.DataFrame([r.data() for r in result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43446a7-524d-4a99-bdf5-ab7d71b56edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_cypher(\"MATCH (n:Participant) RETURN count(n) AS count\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e518a4b-ca16-4bc6-b229-4101a12dac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH (entry:Entry)-[:HAS_VOICE]->(voice:Voice)\n",
    "RETURN voice, entry.date AS date\n",
    "ORDER BY date\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def neo4j_datetime_to_py(datetime_obj):\n",
    "    # Convert neo4j.time.DateTime to Python datetime\n",
    "    return datetime_obj.to_native()\n",
    "\n",
    "def run_cypher(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        records = []\n",
    "        for record in result:\n",
    "            voice_node = record[\"voice\"]\n",
    "            voice_props = dict(voice_node.items())\n",
    "            # Convert neo4j DateTime to Python datetime for the 'date' field\n",
    "            voice_props[\"date\"] = neo4j_datetime_to_py(record[\"date\"])\n",
    "            records.append(voice_props)\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "df = run_cypher(query)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039636e-f03c-4458-8909-69db4e5212f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='date',\n",
    "    y='duration',\n",
    "    title='Voice Notes: Duration over Time',\n",
    "    labels={'date': 'Date', 'duration': 'Duration (seconds)'},\n",
    "    hover_data=df.columns  # Show all data on hover\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8b784-d2c2-4847-85da-9028fe907cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show(\"notebook_connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde9bdf-074b-4e46-bb1d-9bf0851198e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "MATCH (p:Participant)<-[:SENT_BY]-(e:Entry)\n",
    "RETURN p.handle AS handle, count(e) AS entry_count\n",
    "ORDER BY entry_count DESC\n",
    "\"\"\"\n",
    "\n",
    "def run_cypher(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        data = [record.data() for record in result]\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "df_participant_counts = run_cypher(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdacca1-80fe-45fb-a75e-01bb4e41e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_participant_counts,\n",
    "    x='handle',\n",
    "    y='entry_count',\n",
    "    title='Number of Entries per Participant',\n",
    "    labels={'handle': 'Participant Handle', 'entry_count': 'Entry Count'},\n",
    "    text='entry_count'\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "\n",
    "fig.show(\"notebook_connected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748aaa17-3345-4a4c-ae33-d552a074f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voice_properties(tx):\n",
    "    query = \"\"\"\n",
    "    MATCH (v:Voice)\n",
    "    WITH v, keys(v) AS props\n",
    "    UNWIND props AS prop\n",
    "    RETURN DISTINCT prop\n",
    "    \"\"\"\n",
    "    result = tx.run(query)\n",
    "    return [record[\"prop\"] for record in result]\n",
    "\n",
    "with driver.session() as session:\n",
    "    voice_properties = session.read_transaction(get_voice_properties)\n",
    "\n",
    "print(\"Properties on :Voice nodes:\", voice_properties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd652823-30d4-4df9-9a4b-9579cdf0d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voice_file_ids(tx):\n",
    "    query = \"\"\"\n",
    "    MATCH (v:Voice)\n",
    "    WHERE v.fileId IS NOT NULL\n",
    "    RETURN v.fileId AS fileId,\n",
    "           v.transcription IS NOT NULL AS transcribed,\n",
    "           v.embedding IS NOT NULL AS embedded,\n",
    "           v.transcription AS transcription\n",
    "    \"\"\"\n",
    "    result = tx.run(query)\n",
    "    return [\n",
    "        {\n",
    "            \"file_id\": record[\"fileId\"],\n",
    "            \"transcribed\": record[\"transcribed\"],\n",
    "            \"embedded\": record[\"embedded\"],\n",
    "            \"transcription\": record[\"transcription\"]\n",
    "        }\n",
    "        for record in result\n",
    "    ]\n",
    "\n",
    "with driver.session() as session:\n",
    "    file_ids = session.execute_read(get_voice_file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acadda44-2198-4b1c-b72c-144e2cd5534f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f13635-1c8a-428a-9d68-1a1173b3b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34617ec8-0d6f-436b-bca2-154322dd2c5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "API_URL = f\"https://api.telegram.org/bot{BOT_TOKEN}\"\n",
    "FILE_URL = f\"https://api.telegram.org/file/bot{BOT_TOKEN}\"\n",
    "\n",
    "def get_telegram_file_path(file_id):\n",
    "    print(\"getting file path for:\", file_id)\n",
    "    resp = requests.get(f\"{API_URL}/getFile\", params={\"file_id\": file_id})\n",
    "    if resp.status_code == 200:\n",
    "        data = resp.json()\n",
    "        if data[\"ok\"]:\n",
    "            return data[\"result\"][\"file_path\"]\n",
    "    return None\n",
    "\n",
    "def download_telegram_file(file_path, save_dir=\"data\"):\n",
    "    print(\"downloading file for:\", file_path)\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    url = f\"{FILE_URL}/{file_path}\"\n",
    "\n",
    "    filename = Path(file_path).name + \".oga\"\n",
    "    local_filename = Path(save_dir) / filename\n",
    "\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        with open(local_filename, \"wb\") as f:\n",
    "            f.write(resp.content)\n",
    "        return str(local_filename)\n",
    "    else:\n",
    "        print(f\"Failed to download {file_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29554d-88aa-417e-9eb7-0b40e3c26f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voice_files_to_transcribe = []\n",
    "\n",
    "for record in file_ids:  # file_records = get_voice_file_ids(tx)\n",
    "    file_id = record[\"file_id\"]\n",
    "    transcribed = record[\"transcribed\"]\n",
    "    embedded = record[\"embedded\"]\n",
    "    transcription = record[\"transcription\"] or \"\"\n",
    "\n",
    "    tg_file_path = get_telegram_file_path(file_id)\n",
    "    if tg_file_path:\n",
    "        local_file = download_telegram_file(tg_file_path)\n",
    "        if local_file:\n",
    "            voice_files_to_transcribe.append({\n",
    "                \"file_id\": file_id,\n",
    "                \"file_path\": local_file,\n",
    "                \"transcribed\": transcribed,\n",
    "                \"embedded\": embedded,\n",
    "                \"transcription\": transcription\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbe367-1a28-46b4-b4fb-46da39f2880f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai = OpenAI(api_key=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ba801-671b-4029-919d-f8427c43909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path: Path) -> str:\n",
    "    transcription = openai.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=file_path,\n",
    "        language=\"en\"  # Force English transcription\n",
    "    )\n",
    "    return transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178dce08-072f-4c24-bd7c-d2fbe052eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-large\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e083191-c775-457e-a211-4ddfd56671c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_voice_node(tx, file_id, transcription, embedding):\n",
    "    query = \"\"\"\n",
    "    MATCH (v:Voice {fileId: $fileId})\n",
    "    SET v.transcription = $transcription,\n",
    "        v.embedding = $embedding\n",
    "    \"\"\"\n",
    "    tx.run(query, fileId=file_id, transcription=transcription, embedding=embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc773f27-9083-4b10-b9fa-9d57b11e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def update_voice_and_create_chunks(tx, file_id: str, transcription: str, chunks: List[str], embeddings: List[List[float]]):\n",
    "    # 1. Create VoiceChunk nodes with embeddings\n",
    "    for chunk_text, embedding in zip(chunks, embeddings):\n",
    "        # Ensure embedding is a plain list (not numpy array)\n",
    "        if hasattr(embedding, \"tolist\"):\n",
    "            embedding = embedding.tolist()\n",
    "\n",
    "        print(f\"Creating chunk for {file_id}: {chunk_text[:50]!r}\")\n",
    "\n",
    "        tx.run(\"\"\"\n",
    "            MATCH (v:Voice {fileId: $fileId})\n",
    "            CREATE (c:VoiceChunk {\n",
    "              chunk_text: $chunk_text,\n",
    "              embedding: $embedding\n",
    "            })\n",
    "            MERGE (v)-[:HAS_CHUNK]->(c)\n",
    "        \"\"\", fileId=file_id, chunk_text=chunk_text, embedding=embedding).consume()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe42472-34c2-4b67-a9d0-7df153d5177d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "\n",
    "# Setup: text splitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# -- Your modified processing loop --\n",
    "\n",
    "for item in voice_files_to_transcribe:\n",
    "    file_id = item[\"file_id\"]\n",
    "    file_path = item[\"file_path\"]\n",
    "    already_transcribed = item[\"transcribed\"]\n",
    "    already_embedded = item[\"embedded\"]\n",
    "    existing_transcription = item[\"transcription\"]\n",
    "\n",
    "    if not already_transcribed:\n",
    "        transcription = transcribe_audio(Path(file_path))\n",
    "        print(f'This one had no existing transcription: {file_id}')\n",
    "    else:\n",
    "        transcription = existing_transcription\n",
    "\n",
    "    # Step 2: Chunk\n",
    "    chunks = splitter.split_text(transcription)\n",
    "    \n",
    "    # Step 3: Embed chunks\n",
    "    embeddings = [get_embedding(chunk) for chunk in chunks]\n",
    "\n",
    "    # Step 4: Write to database\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(update_voice_and_create_chunks, file_id, transcription, chunks, embeddings)\n",
    "\n",
    "    print(f\"✅ Processed {file_id} into {len(chunks)} chunks\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
