{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a79a946-5727-431a-8abd-ef12e0351800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias Fechner\\Documents\\2_Work\\prisma\\evaluate\\analysis\\notebooks\n",
      "neo4j+s://7a2be29f.databases.neo4j.io\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "env_path = Path('..') / '.env.local'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Retrieve credentials\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "username = os.getenv(\"NEO4J_USER\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "print(uri)\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98f985-87e3-47ec-a096-c219d716ae89",
   "metadata": {},
   "source": [
    "Dont run the below cell unless you want to recreate the index (which isn't necessary unless you have new data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b7a16-31e6-4dcf-a436-528e4e5632df",
   "metadata": {},
   "source": [
    "def drop_vector_index(driver, index_name):\n",
    "    with driver.session() as session:\n",
    "        # Use backticks in case the index name has hyphens\n",
    "        cypher = f\"DROP INDEX `{index_name}` IF EXISTS\"\n",
    "        session.run(cypher)\n",
    "        print(f\"üóëÔ∏è Dropped vector index: {index_name}\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "drop_vector_index(driver, \"voice-vector-index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cfb35c4-8ea9-431f-aef3-d4cabd639c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"voice-vector-index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1bf48-c7aa-4837-962e-c27e6b3553e3",
   "metadata": {},
   "source": [
    "Or these two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bea1d8-96e5-4e82-a71f-8f24c0527d70",
   "metadata": {},
   "source": [
    "# Index parameters\n",
    "NODE_LABEL = \"VoiceChunk\"\n",
    "PROPERTY_NAME = \"embedding\"\n",
    "DIMENSIONS = 3072  # For OpenAI \"text-embedding-3-large\"\n",
    "SIMILARITY_FUNCTION = \"cosine\"  # or 'euclidean' or 'dot'\n",
    "\n",
    "# Create the index\n",
    "def create_vector_index(driver):\n",
    "    cypher = f\"\"\"\n",
    "    CALL db.index.vector.createNodeIndex(\n",
    "        '{INDEX_NAME}',\n",
    "        '{NODE_LABEL}',\n",
    "        '{PROPERTY_NAME}',\n",
    "        {DIMENSIONS},\n",
    "        '{SIMILARITY_FUNCTION}'\n",
    "    )\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        try:\n",
    "            session.run(cypher)\n",
    "            print(f\"‚úÖ Vector index '{INDEX_NAME}' created successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to create vector index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfa12a-f98b-44c8-9b71-8ad58932e279",
   "metadata": {},
   "source": [
    "create_vector_index(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f3b1ac-2563-47a5-b206-577ada883a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "from neo4j_graphrag.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43667405-f91a-4791-818a-02dd50b268bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = VectorRetriever(driver, INDEX_NAME, embedder)\n",
    "\n",
    "# 3. LLM\n",
    "# Note: the OPENAI_API_KEY must be in the env vars\n",
    "llm = OpenAILLM(model_name=\"gpt-4o\", model_params={\"temperature\": 0})\n",
    "\n",
    "# Initialize the RAG pipeline\n",
    "rag = GraphRAG(retriever=retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67837315-2236-4a99-b3e3-1552e4a04f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. University community (including students and licensed counselors)\n",
      "2. Neighborhoods as potential communities\n",
      "3. Investee systems and investor body as a community\n",
      "4. University contacts and referral networks\n",
      "5. Schools and clubs\n"
     ]
    }
   ],
   "source": [
    "# Query the graph\n",
    "query_text = \"List as many tangible stakeholders that were referred to. Exclude Prisma, ARC, Wada and Dream Village. Examples of stakeholders are: companies, communities, institutions, governments etc.\"\n",
    "response = rag.search(query_text=query_text, retriever_config={\"top_k\": 25})\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3605735-f59c-44cc-9ec3-e29d320d6475",
   "metadata": {},
   "source": [
    "### Filter by participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37e16cc-e9be-48b9-bdd4-0a2eabd812da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the organizational entities, stakeholders, and fields of work referred to include:\n",
      "\n",
      "1. **Investees**: Mentioned in the context of focusing on investee systems and reaching out to them. Example: \"we need to reach out to the investee.\"\n",
      "\n",
      "2. **Communities**: Discussed as potential stakeholders, with different types of communities being considered, such as investor bodies and neighborhoods. Example: \"the investor body could be one community. Neighborhoods could be another community.\"\n",
      "\n",
      "3. **Dream Village**: Referred to in the context of expected activities and contributions. Example: \"we also spoke about Dream Village, what we should expect from Dream Village.\"\n",
      "\n",
      "4. **Recycling Companies**: Mentioned in the context of meeting with operation managers. Example: \"we were able to meet the recycling companies. We met the operation managers for two recycling companies.\"\n",
      "\n",
      "5. **Transport Companies**: Briefly mentioned in the context of not needing buses. Example: \"there are transport companies who do not.\"\n",
      "\n",
      "6. **University Bodies**: Discussed as a potential focus area with existing structures and counselors. Example: \"either we are settling on university bodies, okay, which we already have structures in place, have counsellors in place.\"\n",
      "\n",
      "7. **Stakeholders**: General reference to stakeholders involved in solutions and licensing. Example: \"reaching out to the stakeholders, and check their licensing.\"\n",
      "\n",
      "Fields of work include waste management, community projects, and the development of schemas for evaluating contributions and values.\n"
     ]
    }
   ],
   "source": [
    "from neo4j_graphrag.retrievers import VectorCypherRetriever\n",
    "\n",
    "# Cypher to retrieve only facilitator voice reflections\n",
    "retrieval_query = \"\"\"\n",
    "MATCH (node)<-[:HAS_CHUNK]-(v:Voice)<-[:HAS_VOICE]-(e:Entry)-[:SENT_BY]->(p:Participant)\n",
    "WHERE p.role = 'participant'\n",
    "RETURN node.chunk_text AS content, score\n",
    "\"\"\"\n",
    "\n",
    "# Set up the retriever\n",
    "retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name=\"voice-vector-index\",       # Make sure this matches your vector index name\n",
    "    retrieval_query=retrieval_query,\n",
    "    embedder=embedder\n",
    ")\n",
    "\n",
    "# Re-initialize the RAG pipeline\n",
    "rag = GraphRAG(retriever=retriever, llm=llm)\n",
    "\n",
    "# Example query\n",
    "response = rag.search(query_text=\"List all organisational entities, stakeholders and fields of work that were referred to. Examples of stakeholders are: companies, communities, institutions, governments etc. Give an example with real text.\", retriever_config={\"top_k\": 45})\n",
    "\n",
    "# Print results\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8be8f-d4f2-4196-baca-c8dc5a85bced",
   "metadata": {},
   "source": [
    "### Filter by participant AND include chunk parent node for whole context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e407a-7952-4139-8abc-2f9732120699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.types import RetrieverResultItem\n",
    "\n",
    "def result_formatter(record):\n",
    "    chunk = record.get(\"chunk_text\")\n",
    "    full_text = record.get(\"full_transcription\")\n",
    "    score = record.get(\"score\")\n",
    "\n",
    "    # Compose content with chunk + hint of full text\n",
    "    content = f\"Chunk: {chunk}\\n\\nContext: {full_text[:1500]}...\"  # truncate to avoid tokens overflow\n",
    "\n",
    "    return RetrieverResultItem(\n",
    "        content=content,\n",
    "        metadata={\"score\": score}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0bf68-1c67-4285-945d-dd072ccef26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cypher to retrieve only facilitator voice reflections\n",
    "retrieval_query = \"\"\"\n",
    "MATCH (node:VoiceChunk)<-[:HAS_CHUNK]-(v:Voice)\n",
    "MATCH (v)<-[:HAS_VOICE]-(e:Entry)-[:SENT_BY]->(p:Participant)\n",
    "WHERE p.role = 'participant'\n",
    "RETURN\n",
    "  node.chunk_text AS chunk_text,\n",
    "  v.transcription AS full_transcription,\n",
    "  score\n",
    "\"\"\"\n",
    "\n",
    "# Set up the retriever\n",
    "retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    index_name=\"voice-vector-index\",       # Make sure this matches your vector index name\n",
    "    retrieval_query=retrieval_query,\n",
    "    embedder=embedder,\n",
    "    result_formatter=result_formatter\n",
    ")\n",
    "\n",
    "# Re-initialize the RAG pipeline\n",
    "rag = GraphRAG(retriever=retriever, llm=llm)\n",
    "\n",
    "# Example query\n",
    "response = rag.search(query_text=\"What were the main facilitated exercises (workshops, scheduled agenda items, activities, sessions) that the participants found interesting or valuable? Value can be understood in terms of having created a shift in their perspective. Reflective data is favoured. Use only the context provided. Give examples of the reflections for each, using the exact text from the data. Present in the format Session Name: Reflection. Try to retrieve 5 distinct sessions.\", retriever_config={\"top_k\": 25})\n",
    "\n",
    "# Print results\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856be7f8-c660-4c56-85be-c2d5dea51781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd4b03-ed64-413c-8c4f-bff56127737d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
